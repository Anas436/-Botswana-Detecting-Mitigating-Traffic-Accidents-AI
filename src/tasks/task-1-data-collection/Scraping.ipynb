{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ed488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pdfminer.six --user\n",
    "# %pip install PyMuPDF --user\n",
    "# %pip install pillow --user\n",
    "# %pip install pdfplumber --user\n",
    "# %pip install tabula-py\n",
    "# %pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f505825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages, extract_text\n",
    "import pandas as pd\n",
    "import re\n",
    "import fitz \n",
    "import PIL.Image\n",
    "import io\n",
    "import os\n",
    "import pdfplumber\n",
    "import PyPDF2\n",
    "from tabula.io import read_pdf\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8651a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting pdf files's names in a directory and ignoring other files.\n",
    "def get_pdf_files():\n",
    "    folder_path = 'crash and claims reports'\n",
    "    files_names_ext = os.listdir(folder_path)\n",
    "    pdf_files = [f for f in files_names_ext if f.endswith('.pdf')]\n",
    "    global file_names\n",
    "    file_names = [name.replace(\".pdf\", \"\") for name in pdf_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "812726e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a specific folder, if it does not exist\n",
    "def folder_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3154a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Extracting text #########\n",
    "def extract__text():\n",
    "    folder_exists('collected data/texts')\n",
    "    for file in file_names:\n",
    "        text = extract_text('crash and claims reports/'+file+'.pdf')\n",
    "        with open(f\"collected data/texts/{file}.txt\", \"w\") as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a196e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Extracting Images #########\n",
    "def extract__images():\n",
    "    folder_exists('collected data/images')\n",
    "    for file in file_names:\n",
    "        pdf = fitz.open(f'crash and claims reports/{file}.pdf')\n",
    "        os.mkdir(os.path.join('collected data/images/', file))\n",
    "        counter = 1\n",
    "        for i in range(len(pdf)):\n",
    "            page = pdf[i]\n",
    "            images = page.get_images()\n",
    "            for image in images:\n",
    "                base_img = pdf.extract_image(image[0])\n",
    "                image_data = base_img[\"image\"]\n",
    "                img = PIL.Image.open(io.BytesIO(image_data))\n",
    "                extension = base_img[\"ext\"]\n",
    "                img.save(open(f\"collected data/images/{file}/image{counter}.{extension}\", \"wb\"))\n",
    "                counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e50d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Extracting Tables #########\n",
    "def extract__tables():\n",
    "    folder_exists('collected data/tables')\n",
    "    \n",
    "    for file in file_names:\n",
    "        with pdfplumber.open(f'crash and claims reports/{file}.pdf') as pdf:\n",
    "            # Create a new Excel workbook\n",
    "            writer = pd.ExcelWriter(f'collected data/tables/{file}.xlsx')\n",
    "\n",
    "            # Loop through each page in the PDF\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                # Extract the tables from the page\n",
    "                tables = page.extract_tables()\n",
    "\n",
    "                # Loop through each table in the page\n",
    "                for j, table in enumerate(tables):\n",
    "                    if len(table) > 10:\n",
    "                        # Convert the table to a pandas DataFrame\n",
    "                        df = pd.DataFrame(table)\n",
    "\n",
    "                        # Set the sheet name in the workbook\n",
    "                        sheet_name = f'Page {i+1}'\n",
    "                        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae5c1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Extracting Tables #########\n",
    "def extract__tables2():\n",
    "    folder_exists('collected data/tables')\n",
    "    \n",
    "    for file in file_names:\n",
    "        pdf_reader = PyPDF2.PdfReader(f'crash and claims reports/{file}.pdf')\n",
    "        pages = len(pdf_reader.pages)\n",
    "        \n",
    "        writer = pd.ExcelWriter(f'collected data/tables/{file}.xlsx')\n",
    "        \n",
    "        for i in range(pages):\n",
    "            tables = read_pdf(f'crash and claims reports/{file}.pdf', pages= i+1, multiple_tables=True, \n",
    "                              stream=True, guess=False, pandas_options={'header': None})\n",
    "            if(len(tables) == 0):\n",
    "                continue\n",
    "            \n",
    "            for j,table in enumerate(tables):  \n",
    "                sheet_name = f'Page {i+1} table{j+1}'\n",
    "                table.to_excel(writer, sheet_name=sheet_name)\n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be28f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract__text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0a40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract__images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64cbe6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: May 19, 2023 12:40:48 PM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\r\n",
      "WARNING: No Unicode mapping for f_i (31) in font RBUORN+MyriadPro-Bold\r\n",
      "May 19, 2023 12:40:48 PM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\r\n",
      "WARNING: No Unicode mapping for f_i (31) in font RBUORN+MyriadPro-Regular\r\n",
      "May 19, 2023 12:40:48 PM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\r\n",
      "WARNING: No Unicode mapping for f_f_i (30) in font RBUORN+MyriadPro-Bold\r\n",
      "May 19, 2023 12:40:48 PM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\r\n",
      "WARNING: No Unicode mapping for f_f (29) in font RBUORN+MyriadPro-Bold\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_pdf_files()\n",
    "extract__tables2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1292c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
